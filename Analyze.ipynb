{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# this will ensure any change on external py file will be applied instantly\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "from analyze import TextlineTagger\n",
    "\n",
    "\"\"\"\n",
    "Define TextlineTagger based on your analysis need.\n",
    "Tag the textlines with proper tags on your intested lines.\n",
    "Return None if you don't care this textline.\n",
    "\"\"\"\n",
    "class DeleteErrorTagger(TextlineTagger):\n",
    "    def tag_line(self, textline):\n",
    "        if textline.is_debug_line:  # skip rejected/filtered/early_rejected lines\n",
    "            return\n",
    "        if textline.del_err > 0 and all(\n",
    "                c == '*' or c == ' ' for c in textline.hyp\n",
    "        ) and textline.insert_err == 0 and textline.subs_err == 0:\n",
    "            delete_tags = {\"DETECTOR_DELETE\", \"REJECTED\", \"EARLY_REJ\"}\n",
    "            tag = [tag for tag in delete_tags if tag in textline.tags]\n",
    "            assert len(tag) <= 1, tag\n",
    "            if tag:\n",
    "                tag = tag[0]\n",
    "            else:\n",
    "                tag = 'UNK'\n",
    "            return [tag]\n",
    "\n",
    "\n",
    "class CharErrorPairTagger(TextlineTagger):\n",
    "    def tag_line(self, textline):\n",
    "        if textline.is_debug_line:  # skip rejected/filtered/early_rejected lines\n",
    "            return\n",
    "        ref = textline.ref\n",
    "        hyp = textline.hyp\n",
    "        assert len(ref) == len(hyp), textline\n",
    "        cur_pairs = list(\n",
    "            filter(lambda tp: tp[0] != tp[1] and tp[0] != '*' and tp[1] != '*',\n",
    "                   zip(ref, hyp)))\n",
    "        return [f'{pair[0]} -> {pair[1]}' for pair in cur_pairs]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "from analyze import EvalAnalyzer\n",
    "\n",
    "analyzer = EvalAnalyzer()\n",
    "\n",
    "# register the taggers you defined\n",
    "analyzer.register_textline_tagger(DeleteErrorTagger())\n",
    "analyzer.register_textline_tagger(CharErrorPairTagger())\n",
    "\n",
    "alldata_id = '1d48bf6d-d4dc-4cb6-b04a-3df6ef5326e6'\n",
    "baseline_id = 'e8efe255-c62f-4dd2-8a58-8fc4eb417553'\n",
    "script = 'latin_hw'\n",
    "doc_only=False\n",
    "entity = 'TextAnalyticsAPI_Quantity_EntityGroup'\n",
    "\n",
    "# mark each record with an alias name\n",
    "records = [\n",
    "#     ('baseline', baseline_id), \n",
    "    ('alldata', alldata_id),\n",
    "]\n",
    "analysis = analyzer.analyze(records, script, doc_only, entity, 'lv1')\n",
    "\n",
    "# format the result and print\n",
    "formatted = EvalAnalyzer.format(analysis, max_tag_count = 10)\n",
    "for tagger, fmt in formatted.items():\n",
    "    print(tagger)\n",
    "    print(fmt)\n",
    "    print()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "92280it [00:02, 39673.05it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DeleteErrorTagger\n",
      "key      count alldata    percentage alldata\n",
      "-----  ---------------  --------------------\n",
      "UNK               4624                   100\n",
      "\n",
      "CharErrorPairTagger\n",
      "key       count alldata    percentage alldata\n",
      "------  ---------------  --------------------\n",
      ". -> ,              636                  5.82\n",
      ", -> .              607                  5.56\n",
      "1 -> /              427                  3.91\n",
      "0 -> .              264                  2.42\n",
      "0 -> O              252                  2.31\n",
      "0 -> o              224                  2.05\n",
      "1 -> -              223                  2.04\n",
      "1 -> .              213                  1.95\n",
      ". -> -              164                  1.5\n",
      "5 -> S              162                  1.48\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}